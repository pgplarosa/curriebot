{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04abda4a-526e-4e65-95bb-4c516c5c43ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -qq gradio==3.48.0\n",
    "# !pip install -qq fastapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "667748eb-7111-494f-9aa2-e1ea86ea53b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to copy all py scripts in the same directory\n",
    "import os\n",
    "import logging\n",
    "import openai\n",
    "import gradio as gr\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from curriebot import get_agent_executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34052687-9fd6-4628-87bc-6d5a73995237",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig()\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9d669bb-5a8e-4f65-98ad-47fd8e8dfe85",
   "metadata": {},
   "outputs": [],
   "source": [
    "intro_message = \"\"\"**Meet Curriebot, your personal career companion! \n",
    "Curriebot is here to help you navigate through my professional journey/\"Curri\"culum vitae, \n",
    "answering all your questions about my resume or personal projects. \n",
    "Whether you're curious about the details of my project or want insights into my skill set, \n",
    "Curriebot is ready to chat. Friendly and knowledgeable, \n",
    "Curriebot makes learning about my professional life both easy and enjoyable. \n",
    "Let's get the conversation started!**\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf8d9347-ac6e-4f99-a81a-29c88dc7c99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "assitant_initial_message = \"\"\"Hi, my name is Curriebot. Thank you for stopping by. \n",
    "I'm here to assist you with any questions about Patrick's resume or projects. How can I help you today?\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "874186a7-57b9-4536-aa7d-d5c5377a5fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27218/3006030071.py:48: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.\n",
      "  chatbot = gr.Chatbot([(None, assitant_initial_message)]).style(height=500)\n",
      "/tmp/ipykernel_27218/3006030071.py:63: GradioDeprecationWarning: The `enable_queue` parameter has been deprecated. Please use the `.queue()` method instead.\n",
      "  demo.launch(share=True, debug=True, enable_queue=True).queue()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "IMPORTANT: You are using gradio version 3.48.0, however version 4.29.0 is available, please upgrade.\n",
      "--------\n",
      "Running on public URL: https://9728eaa3e658e962b3.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://9728eaa3e658e962b3.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "/home/ubuntu/.conda/envs/curriebot_nb/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The function `format_tool_to_openai_tool` was deprecated in LangChain 0.1.16 and will be removed in 0.3.0. Use langchain_core.utils.function_calling.convert_to_openai_tool() instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Hello! How can I assist you today?' response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 8, 'total_tokens': 17}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-866dbcc4-d9bd-47da-8450-914a5d6f1b34-0'\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mHello! How can I assist you today? If you have any questions about Patrick's resume, work experience, or personal projects, feel free to ask!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mHello Mario! How can I assist you today? If you have any questions about Patrick's resume, work experience, or projects, feel free to ask!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mYour name is Mario, as you previously mentioned. How may I assist you further?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `resume_qa` with `{'user_query': 'what is my name again?'}`\n",
      "\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "INFO:chromadb.api.segment:Collection langchain is not created.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:langchain.retrievers.self_query.base:Generated Query: query='what is my name again' filter=None limit=None\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3mThe name on the resume is Patrick Guillano La Rosa.\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mYour name is Patrick Guillano La Rosa.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Keyboard interruption in main thread... closing server.\n",
      "Killing tunnel 127.0.0.1:7860 <> https://9728eaa3e658e962b3.gradio.live\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'TupleNoPrint' object has no attribute 'queue'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 63\u001b[0m\n\u001b[1;32m     57\u001b[0m     clear\u001b[38;5;241m.\u001b[39mclick(fn\u001b[38;5;241m=\u001b[39mclear_memory_agent)\n\u001b[1;32m     59\u001b[0m     msg\u001b[38;5;241m.\u001b[39msubmit(respond, [msg, chatbot], [msg, chatbot])\n\u001b[0;32m---> 63\u001b[0m \u001b[43mdemo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlaunch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshare\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menable_queue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqueue\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TupleNoPrint' object has no attribute 'queue'"
     ]
    }
   ],
   "source": [
    "def clear_memory_agent():\n",
    "    global agent_executor\n",
    "    agent_executor = get_agent_executor()\n",
    "\n",
    "def start_chat(api_key):\n",
    "    global agent_executor\n",
    "    try:\n",
    "        os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "        openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "        print(llm.invoke(\"hi\"))\n",
    "        gr.Info(\"openai api key authentication successful!\")\n",
    "        \n",
    "        agent_executor = get_agent_executor()\n",
    "        return {\n",
    "            start_col: gr.Column(visible=False),\n",
    "            chat_col : gr.Column(visible=True),\n",
    "        }\n",
    "    except Exception as e:\n",
    "        raise gr.Error(\"Please double check your openai api key!\")\n",
    "\n",
    "    \n",
    "\n",
    "def respond(message, chat_history):\n",
    "        result = agent_executor.invoke({\"input\": message})\n",
    "        chat_history.append((result[\"input\"], result[\"output\"]))\n",
    "        \n",
    "        return \"\", chat_history\n",
    "\n",
    "with gr.Blocks(\n",
    "    theme=gr.themes.Default(\n",
    "        font=gr.themes.GoogleFont(\"Source Sans Pro\"),\n",
    "        font_mono=gr.themes.GoogleFont(\"Source Sans Pro\"),\n",
    "    )\n",
    ") as demo:\n",
    "    agent_executor = None\n",
    "    gr.Label(\"Curriebot\")\n",
    "    gr.Markdown(intro_message)\n",
    "    gr.Markdown(\"Before we begin. Please enter your openai api key. Don't worry I will not save it for personal use\")\n",
    "    \n",
    "    with gr.Row(visible=True) as start_row:\n",
    "        with gr.Column(visible=True) as start_col:\n",
    "            api_key = gr.Textbox(label=\"Enter openai api key here\", type=\"password\")\n",
    "            start_button = gr.Button(\"Start Chat!\")\n",
    "\n",
    "    with gr.Row(visible=True) as chat_row:\n",
    "        with gr.Column(visible=False) as chat_col:\n",
    "            chatbot = gr.Chatbot([(None, assitant_initial_message)]).style(height=500)\n",
    "            msg = gr.Textbox()\n",
    "            clear = gr.ClearButton([msg, chatbot])\n",
    "\n",
    "    \n",
    "    start_button.click(\n",
    "        fn=start_chat, inputs=[api_key], outputs=[start_col, chat_col]\n",
    "    )\n",
    "\n",
    "    clear.click(fn=clear_memory_agent)\n",
    "    \n",
    "    msg.submit(respond, [msg, chatbot], [msg, chatbot])\n",
    "\n",
    "    \n",
    "\n",
    "demo.launch(share=True, debug=True, enable_queue=True).queue()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8de69b-3fbc-4658-be98-52e23144ba6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b46c6fa-a0a0-405c-8b49-e7daeb22bc31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
